<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shihua Huang</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon_clipart.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shihua Huang (黄世华)</name>
              </p>
              <p>
                Shihua Huang is currently a PhD candidate with the Dept. of Computing at Hong Kong Polytechnic University, Hong Kong, China.
                </p>
              <p>
                His research interests are in the field of representation learning, notably neural architecture search, deep learning assisted evolutionary algorithms,
                and in particular dense image prediction (auto-driving and medical image analysis).
              </p>
              <p style="text-align:center">
                <a href="mailto:shihuahuang95@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/ShihuaHuangCV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/ShihuaHuang-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=YVZLfBUAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ShihuaHuang95/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/shihua_huang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shihua_huang_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fpn_vs_fapn.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.shihuahuang.cn/fapn">
                <papertitle>FaPN: Feature-aligned Pyramid Network for Dense Image Prediction</papertitle>
              </a>
              <br>
              <strong>Shihua Huang</strong>,
              <a href="http://www.luzhichao.com/">Zhichao Lu</a>,
              <a href="https://scholar.google.com/citations?user=bjeIdlcAAAAJ&hl=en&oi=ao">Ran Cheng</a>,
              <a href="https://www.chenghehust.com/">Cheng He</a>,
              <br>
							<em>ICCV</em>, 2021 &nbsp
              <br>
              <a href="http://www.shihuahuang.cn/fapn">project page</a>
              /
              <a href="https://arxiv.org/abs/2108.07058">arXiv</a>
<!--              /-->
<!--              <a href="https://youtu.be/EpH175PY1A0">video</a>-->
							/
              <a href="https://github.com/ShihuaHuang95/FaPN">code</a>
              <p></p>
              <p>FaPN a simple yet effective top-down pyramidal architecture to generate multi-scale features for dense image prediction.
                It improves FPN's AP / mIoU by 1.5 - 2.6% on all tasks. It achieved 56.7% mIoU over ADE20k-150 when paired with MaskFormer.</p>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:2px;width:15%;vertical-align:middle"><img src="images/IEEE.jpg"></td>
            <td width="85%" valign="center">
              Reviewer, Trans. on Multi Media, Trans. on Cognitive and Developmental Systems
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
